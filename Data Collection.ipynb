{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ea1bd8",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "To begin the data analysis and machine learning workflow, we import essential Python libraries for data manipulation, visualization, and numerical operations:\n",
    "\n",
    "### Libraries Used:\n",
    "- **pandas**: For reading, cleaning, and processing structured data (DataFrames).\n",
    "- **numpy**: For efficient numerical computations and array operations.\n",
    "- **seaborn**: For enhanced data visualization with statistical plotting.\n",
    "- **matplotlib.pyplot**: For creating custom plots and charts.\n",
    "\n",
    "These libraries form the core environment for exploring the dataset and preparing it for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe57f63e-e164-4292-9e0b-53bcc6e12c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd6251",
   "metadata": {},
   "source": [
    "## Loading Air Quality and Weather Datasets\n",
    "\n",
    "We begin by loading two separate datasets: one containing **air quality data** and another with **weather conditions**. These datasets are later merged to build a comprehensive view for AQI prediction.\n",
    "\n",
    "### Datasets:\n",
    "- **Air Quality Data (`aqidf`)**\n",
    "  - File: `city-railway station, bangalore-air-quality.csv`\n",
    "  - Contains pollutant concentrations (e.g., PM10, NO₂, SO₂) and AQI values recorded near a railway station in Bangalore.\n",
    "\n",
    "- **Weather Data (`weatherdf`)**\n",
    "  - File: `climate_data.csv`\n",
    "  - Includes meteorological parameters such as temperature, humidity, rainfall, fog, and wind speed.\n",
    "\n",
    "Both datasets are read using `pandas.read_csv()` and will be preprocessed and merged in subsequent steps to create a unified dataset for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbcf774-0053-4aa4-b63d-e25704faf3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqidf = pd.read_csv(r\"D:\\Downloads\\city-railway station, bangalore-air-quality.csv\")\n",
    "weatherdf = pd.read_csv(r\"D:\\Downloads\\climate_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f672b",
   "metadata": {},
   "source": [
    "## Previewing the Air Quality Dataset\n",
    "\n",
    "To understand the structure and contents of the air quality data, we use the `head()` function to display the first few rows of the DataFrame.\n",
    "\n",
    "### Purpose:\n",
    "- To inspect the available features (columns) such as pollutant concentrations and AQI values.\n",
    "- To check for any missing values, data types, or formatting issues.\n",
    "- To verify the successful loading of the dataset.\n",
    "\n",
    "This preview helps guide the data cleaning and feature engineering steps that follow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f2139f-8815-4438-bb65-5a5ded1db5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm10</th>\n",
       "      <th>no2</th>\n",
       "      <th>so2</th>\n",
       "      <th>co</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm10  no2  so2  co  Day  Month  Year\n",
       "0    69   18    3  10    1      3  2025\n",
       "1    71   18    3   9    2      3  2025\n",
       "2    70   16    3   9    3      3  2025\n",
       "3    72   12    4  11    4      3  2025\n",
       "4    73   11    4  11    5      3  2025"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3a502",
   "metadata": {},
   "source": [
    "## Previewing the Weather Dataset\n",
    "\n",
    "We use the `head()` function to examine the first few rows of the weather dataset.\n",
    "\n",
    "### Purpose:\n",
    "- To explore the structure and types of weather-related features available.\n",
    "- To verify the presence of key variables such as temperature, humidity, wind speed, rainfall, and fog.\n",
    "- To confirm successful data loading and assess if any initial cleaning is required.\n",
    "\n",
    "This preview ensures we understand how weather variables are recorded and prepares us for merging with the air quality data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f12195a-e11b-4b1c-8c9b-30de75ba813e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>PP</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>VG</th>\n",
       "      <th>RA</th>\n",
       "      <th>SN</th>\n",
       "      <th>TS</th>\n",
       "      <th>FG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>25.3</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>27.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>-</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day     T    TM    Tm  SLP    H   PP   VV    V    VM   VG  \\\n",
       "0  2006      1  1.0  19.3  25.3  13.4    -   70    0  6.6  5.7   9.4    -   \n",
       "1  2006      1  2.0  19.5  25.5  14.5    -   69    0  6.6  5.7   9.4    -   \n",
       "2  2006      1  3.0  20.6  27.6  15.8    -   60    0  6.3  4.8  11.1    -   \n",
       "3  2006      1  4.0   NaN   NaN   NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN   \n",
       "4  2006      1  5.0   NaN   NaN   NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN   \n",
       "\n",
       "    RA   SN   TS   FG  \n",
       "0  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c06ac3-d7c7-4945-aaf1-792151faf409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7261 entries, 0 to 7260\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Year    7261 non-null   int64  \n",
      " 1   Month   7261 non-null   int64  \n",
      " 2   Day     7030 non-null   float64\n",
      " 3   T       3868 non-null   object \n",
      " 4   TM      3868 non-null   object \n",
      " 5   Tm      3868 non-null   object \n",
      " 6   SLP     3868 non-null   object \n",
      " 7   H       3868 non-null   object \n",
      " 8   PP      3868 non-null   object \n",
      " 9   VV      3868 non-null   object \n",
      " 10  V       3868 non-null   object \n",
      " 11  VM      3868 non-null   object \n",
      " 12  VG      3637 non-null   object \n",
      " 13  RA      2674 non-null   object \n",
      " 14  SN      314 non-null    object \n",
      " 15  TS      874 non-null    object \n",
      " 16  FG      327 non-null    object \n",
      "dtypes: float64(1), int64(2), object(14)\n",
      "memory usage: 964.5+ KB\n"
     ]
    }
   ],
   "source": [
    "weatherdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9482054-9351-42cb-a524-5c586b32799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2798 entries, 0 to 2797\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0    pm10   2798 non-null   object\n",
      " 1    no2    2798 non-null   object\n",
      " 2    so2    2798 non-null   object\n",
      " 3    co     2798 non-null   object\n",
      " 4   Day     2798 non-null   int64 \n",
      " 5   Month   2798 non-null   int64 \n",
      " 6   Year    2798 non-null   int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 153.1+ KB\n"
     ]
    }
   ],
   "source": [
    "aqidf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91374d8",
   "metadata": {},
   "source": [
    "## Cleaning the Weather Dataset\n",
    "\n",
    "To ensure consistency and avoid issues during merging or analysis, we remove any rows from the weather dataset where the **`Day`** value is missing.\n",
    "\n",
    "### Operation:\n",
    "- `dropna(subset=['Day'])`: Removes rows where the `Day` column contains `NaN`.\n",
    "\n",
    "### Purpose:\n",
    "- The `Day` column is essential for time-based merging with the air quality dataset.\n",
    "- Missing date components can lead to mismatches or invalid entries during join operations.\n",
    "\n",
    "This step ensures the weather dataset contains only valid, complete date entries before proceeding with further processing or merging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a510e755-31d9-4193-a5c5-aa44b5b2c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherdf = weatherdf.dropna(subset=['Day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6c10f9",
   "metadata": {},
   "source": [
    "## Converting 'Day' Column to Integer\n",
    "\n",
    "To ensure uniformity in data types and support accurate merging with other datasets, we convert the `Day` column in the weather dataset to integers.\n",
    "\n",
    "### Operation:\n",
    "- `astype(int)`: Casts all values in the `Day` column to integer type.\n",
    "\n",
    "### Purpose:\n",
    "- Aligns the `Day` column with date columns in the air quality dataset, which are often stored as integers.\n",
    "- Prevents issues during filtering, comparisons, or merging operations that depend on date alignment.\n",
    "\n",
    "This step is part of standardizing temporal fields across datasets before merging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c04e76d-7f13-4747-bf6d-ed5632d1ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherdf['Day'] = weatherdf['Day'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513275b9",
   "metadata": {},
   "source": [
    "## Merging Weather and Air Quality Datasets\n",
    "\n",
    "To build a unified dataset for AQI prediction, we merge the **weather** and **air quality** datasets based on common temporal keys.\n",
    "\n",
    "### Merge Details:\n",
    "- **Keys Used**: `Year`, `Month`, and `Day`\n",
    "- **Merge Type**: `inner`\n",
    "  - Ensures only rows with matching dates in both datasets are retained.\n",
    "\n",
    "### Purpose:\n",
    "- Combines meteorological features (from `weatherdf`) with pollutant and AQI values (from `aqidf`).\n",
    "- Creates a single dataset (`merge_df`) that can be used for feature engineering and model training.\n",
    "\n",
    "This merged dataset forms the foundation for all subsequent analysis and modeling tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "370386c1-8997-42ea-97ec-8a4751ee306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(weatherdf, aqidf, on=['Year','Month','Day'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df98b7c2",
   "metadata": {},
   "source": [
    "## Previewing the Merged Dataset\n",
    "\n",
    "After merging the weather and air quality datasets, we use `head()` to examine the first few rows of the resulting DataFrame `merge_df`.\n",
    "\n",
    "### Purpose:\n",
    "- To verify that the merge was successful.\n",
    "- To ensure that both weather and air quality features are present and properly aligned.\n",
    "- To check for any inconsistencies or issues introduced during the merge process.\n",
    "\n",
    "This step confirms the integrity of the combined dataset before proceeding with cleaning, feature engineering, or modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed25985-6312-4456-bb9a-04066a6df2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>PP</th>\n",
       "      <th>VV</th>\n",
       "      <th>...</th>\n",
       "      <th>VM</th>\n",
       "      <th>VG</th>\n",
       "      <th>RA</th>\n",
       "      <th>SN</th>\n",
       "      <th>TS</th>\n",
       "      <th>FG</th>\n",
       "      <th>pm10</th>\n",
       "      <th>no2</th>\n",
       "      <th>so2</th>\n",
       "      <th>co</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>62</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>28.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.4</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>29</td>\n",
       "      <td>13.7</td>\n",
       "      <td>-</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day     T    TM    Tm  SLP    H   PP   VV  ...   VM   VG   RA  \\\n",
       "0  2015     12   29   NaN   NaN   NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "1  2015     12   30   NaN   NaN   NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "2  2015     12   31     -     -     -    -    -    -    -  ...    -    -    -   \n",
       "3  2016      1    2  20.8  28.3  12.9    -   45    0  6.3  ...  5.4    -  NaN   \n",
       "4  2016      1    3  21.4    29  13.7    -   45    0  6.3  ...  3.5    -  NaN   \n",
       "\n",
       "    SN   TS   FG  pm10  no2  so2  co  \n",
       "0  NaN  NaN  NaN         48    6  17  \n",
       "1  NaN  NaN  NaN    49   54    7  21  \n",
       "2    -    -    -    62                \n",
       "3  NaN  NaN  NaN         60    9  15  \n",
       "4  NaN  NaN  NaN    79   45   10  13  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473a872",
   "metadata": {},
   "source": [
    "## Inspecting the End of the Merged Dataset\n",
    "\n",
    "We use `tail()` to view the last few rows of the merged DataFrame `merge_df`.\n",
    "\n",
    "### Purpose:\n",
    "- To confirm that the dataset extends consistently across the expected date range.\n",
    "- To identify any irregularities or missing data toward the end of the dataset.\n",
    "- To ensure temporal consistency in both weather and air quality features after merging.\n",
    "\n",
    "This helps validate the completeness of the dataset and ensures it's ready for further preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99cd5240-558b-4353-af6b-0ec0c5f74ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>PP</th>\n",
       "      <th>VV</th>\n",
       "      <th>...</th>\n",
       "      <th>VM</th>\n",
       "      <th>VG</th>\n",
       "      <th>RA</th>\n",
       "      <th>SN</th>\n",
       "      <th>TS</th>\n",
       "      <th>FG</th>\n",
       "      <th>pm10</th>\n",
       "      <th>no2</th>\n",
       "      <th>so2</th>\n",
       "      <th>co</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>66</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>72</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month  Day  T TM Tm SLP  H PP VV  ... VM VG RA SN TS FG  pm10  \\\n",
       "2793  2025      3   20  -  -  -   -  -  -  -  ...  -  -  -  -  -  -    70   \n",
       "2794  2025      3   21  -  -  -   -  -  -  -  ...  -  -  -  -  -  -    70   \n",
       "2795  2025      3   22  -  -  -   -  -  -  -  ...  -  -  -  -  -  -    69   \n",
       "2796  2025      3   23  -  -  -   -  -  -  -  ...  -  -  -  -  -  -    66   \n",
       "2797  2025      3   23  -  -  -   -  -  -  -  ...  -  -  -  -  -  -    72   \n",
       "\n",
       "       no2  so2    co  \n",
       "2793    12    4    12  \n",
       "2794    11    4    12  \n",
       "2795    11    3    14  \n",
       "2796                   \n",
       "2797  11.2  3.5  19.9  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb3aacf",
   "metadata": {},
   "source": [
    "## Handling Missing Values in the Merged Dataset\n",
    "\n",
    "To ensure the dataset is complete and ready for modeling, we apply forward-fill and backward-fill techniques to handle any remaining missing values.\n",
    "\n",
    "### Operations:\n",
    "- `ffill(inplace=True)`: **Forward fill** – propagates the last valid value forward.\n",
    "- `bfill(inplace=True)`: **Backward fill** – fills missing values by propagating the next valid value backward.\n",
    "\n",
    "### Purpose:\n",
    "- Ensures no gaps remain in the dataset after merging.\n",
    "- Maintains temporal consistency by filling based on adjacent days.\n",
    "- Prevents errors or information loss during feature engineering and model training.\n",
    "\n",
    "These steps help create a fully populated dataset without removing rows, preserving as much data as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfa772c3-cdbe-45f1-ba78-c661d18570e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.ffill(inplace=True)\n",
    "merge_df.bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbfc8613-8cf1-4b1e-b6cb-1d2118843c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2798 entries, 0 to 2797\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Year    2798 non-null   int64 \n",
      " 1   Month   2798 non-null   int64 \n",
      " 2   Day     2798 non-null   int32 \n",
      " 3   T       2798 non-null   object\n",
      " 4   TM      2798 non-null   object\n",
      " 5   Tm      2798 non-null   object\n",
      " 6   SLP     2798 non-null   object\n",
      " 7   H       2798 non-null   object\n",
      " 8   PP      2798 non-null   object\n",
      " 9   VV      2798 non-null   object\n",
      " 10  V       2798 non-null   object\n",
      " 11  VM      2798 non-null   object\n",
      " 12  VG      2798 non-null   object\n",
      " 13  RA      2798 non-null   object\n",
      " 14  SN      2798 non-null   object\n",
      " 15  TS      2798 non-null   object\n",
      " 16  FG      2798 non-null   object\n",
      " 17   pm10   2798 non-null   object\n",
      " 18   no2    2798 non-null   object\n",
      " 19   so2    2798 non-null   object\n",
      " 20   co     2798 non-null   object\n",
      "dtypes: int32(1), int64(2), object(18)\n",
      "memory usage: 448.2+ KB\n"
     ]
    }
   ],
   "source": [
    "merge_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999f0c4",
   "metadata": {},
   "source": [
    "## Replacing Placeholder Values with NaN\n",
    "\n",
    "In the merged dataset, some missing or invalid entries may be represented as the string `\"-\"` instead of actual `NaN` values. We replace these placeholders to standardize missing value representation.\n",
    "\n",
    "### Operation:\n",
    "- `replace(\"-\", np.nan, inplace=True)`: Converts all occurrences of `\"-\"` to `np.nan`.\n",
    "\n",
    "### Purpose:\n",
    "- Ensures consistency in how missing values are handled.\n",
    "- Allows functions like `.fillna()`, `.dropna()`, and imputation strategies to work correctly.\n",
    "- Prepares the dataset for numeric conversion and further analysis.\n",
    "\n",
    "This step is crucial before converting columns to numeric types or applying any statistical methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bdd24be-ff85-4a5f-9555-514b07ecee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.replace(\"-\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398dbf63",
   "metadata": {},
   "source": [
    "## Dropping Unnecessary Columns\n",
    "\n",
    "To streamline the dataset and focus on relevant features for AQI prediction, we remove columns that are not useful for modeling.\n",
    "\n",
    "### Operation:\n",
    "- `drop(columns=['SLP', 'VG', 'SN'], inplace=True)`\n",
    "\n",
    "### Purpose:\n",
    "- **`SLP` (Sea Level Pressure)**, **`VG` (Wind Gust)**, and **`SN` (Snowfall)** may be irrelevant, contain too many missing values, or show low correlation with AQI.\n",
    "- Reduces dimensionality and potential noise in the model.\n",
    "- Simplifies the feature set for more efficient processing and interpretation.\n",
    "\n",
    "This cleanup step ensures that only meaningful features are retained for further analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11734508-a6f9-44c2-be17-28f2d1b77e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.drop(columns=['SLP','VG','SN'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf8f399",
   "metadata": {},
   "source": [
    "## Removing Data from the Year 2015\n",
    "\n",
    "To ensure the dataset contains only reliable and relevant observations, we remove all rows corresponding to the year 2015.\n",
    "\n",
    "### Operation:\n",
    "- `merge_df.drop(merge_df[merge_df['Year'] == 2015].index, inplace=True)`\n",
    "\n",
    "### Purpose:\n",
    "- The 2015 data may be incomplete, inconsistent, or out of scope for the modeling timeline.\n",
    "- Helps focus analysis and modeling efforts on more recent and robust data.\n",
    "- Prevents potential biases or inaccuracies caused by early, sparse records.\n",
    "\n",
    "This step refines the temporal scope of the dataset and improves overall data quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6abe5e0-603d-4402-88d1-0175c33897f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.drop(merge_df[merge_df['Year']==2015].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00f753",
   "metadata": {},
   "source": [
    "## Exploring Rainfall (`RA`) Value Distribution\n",
    "\n",
    "To understand the distribution of rainfall data in the merged dataset, we use the `value_counts()` method on the `RA` (Rainfall) column.\n",
    "\n",
    "### Purpose:\n",
    "- Identify how frequently different rainfall values occur.\n",
    "- Detect dominant values (e.g., zero rainfall days).\n",
    "- Spot anomalies or inconsistent entries that may need cleaning or conversion.\n",
    "\n",
    "This step provides insight into how rainfall varies in the dataset and informs decisions for feature transformation or binning, if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96fa57e0-aae7-44af-a5e8-50e0b5078aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RA\n",
       "o    2548\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df['RA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d324a05",
   "metadata": {},
   "source": [
    "## Cleaning and Converting the Rainfall (`RA`) Column\n",
    "\n",
    "The `RA` (Rainfall) column contains inconsistent values and missing data, which we clean and standardize for further analysis.\n",
    "\n",
    "### Steps:\n",
    "1. **Replace Inconsistent Value**:\n",
    "   - `'o'` (a likely typo or placeholder) is replaced with `1` using `replace({'o': 1})`.\n",
    "\n",
    "2. **Fill Missing Values**:\n",
    "   - Missing rainfall values (`NaN`) are filled with `0`, assuming no rainfall on those days.\n",
    "\n",
    "3. **Convert to Integer**:\n",
    "   - The column is cast to `int` to ensure it holds clean, numeric values for modeling.\n",
    "\n",
    "### Purpose:\n",
    "- Ensures the `RA` column is numeric, consistent, and free of invalid entries.\n",
    "- Prepares the feature for numerical analysis and machine learning input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49bd563b-ca08-462d-9013-a60846ef361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df['RA']=merge_df['RA'].replace({'o':1})\n",
    "merge_df['RA']= merge_df['RA'].fillna(0)\n",
    "merge_df['RA'] = merge_df['RA'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0891b1ce",
   "metadata": {},
   "source": [
    "## Exploring Thunderstorm (`TS`) Value Distribution\n",
    "\n",
    "To examine how thunderstorm data is recorded in the dataset, we use `value_counts()` on the `TS` column.\n",
    "\n",
    "### Purpose:\n",
    "- Understand how frequently thunderstorms (`TS`) occur in the dataset.\n",
    "- Identify patterns such as binary indicators (`0` for no thunderstorm, `1` for presence).\n",
    "- Detect any non-standard entries or missing values that may need cleaning.\n",
    "\n",
    "This step helps determine whether the `TS` column can be used as-is or requires transformation before modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbdedbe",
   "metadata": {},
   "source": [
    "## Cleaning and Converting the Thunderstorm (`TS`) Column\n",
    "\n",
    "The `TS` column, which indicates thunderstorm activity, contains inconsistent and missing values. We clean and standardize it to prepare for analysis.\n",
    "\n",
    "### Steps:\n",
    "1. **Replace Non-Standard Values**:\n",
    "   - Replace `'o'` (likely representing presence of thunderstorm) with `1`.\n",
    "\n",
    "2. **Fill Missing Values**:\n",
    "   - Fill all `NaN` values with `0`, assuming no thunderstorm occurred when data is missing.\n",
    "\n",
    "3. **Convert to Integer**:\n",
    "   - Cast the column to `int` type to ensure consistency and compatibility with modeling tools.\n",
    "\n",
    "### Purpose:\n",
    "- Creates a clean, binary indicator for thunderstorm presence.\n",
    "- Ensures the feature is ready for machine learning as a numeric variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d67fa99-1050-4e69-a848-8ed8b9cf7b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TS\n",
       "o    2350\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df['TS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a375f",
   "metadata": {},
   "source": [
    "## Reapplying Cleaning on the Thunderstorm (`TS`) Column\n",
    "\n",
    "This block ensures the `TS` (Thunderstorm) column is fully cleaned and formatted for use in modeling. If already cleaned previously, this acts as a safeguard.\n",
    "\n",
    "### Operations:\n",
    "1. **Replace `'o'` with `1`**: Ensures any lingering non-standard entries are handled.\n",
    "2. **Fill Missing Values with `0`**: Guarantees no null entries remain.\n",
    "3. **Convert to Integer**: Finalizes the column as a binary numeric indicator.\n",
    "\n",
    "### Purpose:\n",
    "- Reinforces data integrity before further processing or modeling.\n",
    "- Ensures the `TS` column is clean, consistent, and usable for feature analysis or training.\n",
    "\n",
    "This step helps eliminate any overlooked inconsistencies that might affect downstream tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b461c667-9ced-4d2e-8eaf-aa7494eeb471",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df['TS']=merge_df['TS'].replace({'o':1})\n",
    "merge_df['TS']= merge_df['TS'].fillna(0)\n",
    "merge_df['TS'] = merge_df['TS'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655e223",
   "metadata": {},
   "source": [
    "## Exploring Fog (`FG`) Value Distribution\n",
    "\n",
    "To assess how fog presence is recorded in the dataset, we use `value_counts()` on the `FG` (Fog) column.\n",
    "\n",
    "### Purpose:\n",
    "- Understand the frequency of foggy days in the dataset.\n",
    "- Detect whether fog data is encoded as binary (`0` for no fog, `1` for fog) or uses other representations.\n",
    "- Identify any unusual or inconsistent values that may require cleaning.\n",
    "\n",
    "This step provides insight into the distribution and reliability of fog-related data for potential use as a predictive feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98ae2e50-4d95-4899-bd24-c72769385d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FG\n",
       "o    1609\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df['FG'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5e268",
   "metadata": {},
   "source": [
    "## Cleaning and Converting the Fog (`FG`) Column\n",
    "\n",
    "The `FG` column, representing fog presence, contains inconsistent and missing values. We standardize it for use in analysis and modeling.\n",
    "\n",
    "### Steps:\n",
    "1. **Replace Non-Standard Values**:\n",
    "   - Replace `'o'` (likely indicating fog) with `1`.\n",
    "\n",
    "2. **Fill Missing Values**:\n",
    "   - Fill all `NaN` values with `0`, assuming no fog when data is missing.\n",
    "\n",
    "3. **Convert to Integer**:\n",
    "   - Convert the column to `int` type to ensure a consistent binary representation.\n",
    "\n",
    "### Purpose:\n",
    "- Transforms the `FG` column into a clean binary indicator (1 for fog, 0 for no fog).\n",
    "- Ensures the feature is ready for modeling and compatible with numerical processing tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fafa0183-2175-4469-9683-ec1b658a4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df['FG']=merge_df['FG'].replace({'o':1})\n",
    "merge_df['FG']= merge_df['FG'].fillna(0)\n",
    "merge_df['FG'] = merge_df['FG'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79043e95",
   "metadata": {},
   "source": [
    "## Dropping Rows with Missing Key Weather Features\n",
    "\n",
    "To ensure data quality and consistency for modeling, we remove any rows that are missing critical weather features.\n",
    "\n",
    "### Operation:\n",
    "- `dropna(subset=['T', 'VV', 'VM'])`: Drops rows where any of the following columns contain `NaN`:\n",
    "  - `T`: Average Temperature\n",
    "  - `VV`: Visibility\n",
    "  - `VM`: Maximum Wind Speed\n",
    "\n",
    "### Purpose:\n",
    "- These features are essential for understanding weather conditions and their effect on air quality.\n",
    "- Ensures the model is trained on complete and reliable data.\n",
    "- Prevents errors during feature engineering or training due to missing values.\n",
    "\n",
    "This step finalizes the dataset with only complete records for key environmental indicators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "266feffb-bc90-4a36-9cc5-31156e13e524",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = merge_df.dropna(subset=['T','VV','VM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151839fb",
   "metadata": {},
   "source": [
    "## Exploring Unique Values Across All Columns\n",
    "\n",
    "To gain a comprehensive understanding of the data, we extract and examine the unique values present in each column of the merged dataset.\n",
    "\n",
    "### Operation:\n",
    "- `merge_df.apply(pd.Series.unique)`: Applies the `unique()` function to each column to retrieve all distinct values.\n",
    "\n",
    "### Purpose:\n",
    "- Identify categorical or binary features (e.g., `FG`, `TS`).\n",
    "- Detect potential data quality issues or inconsistencies.\n",
    "- Understand the range and diversity of values, which can inform encoding decisions and feature transformations.\n",
    "\n",
    "This step is useful for both exploratory data analysis and preparing the dataset for machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a31801c4-5901-44f7-82e4-aafd64870af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year     [2016, 2017, 2018, 2019, 2020, 2021, 2022, 202...\n",
      "Month              [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 5]\n",
      "Day      [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 17, 18, 19, 2...\n",
      "T        [20.8, 21.4, 21, 20.4, 20.7, 21.2, 22.6, 22.9,...\n",
      "TM       [28.3, 29, 28.7, 27.6, 28.4, 25.9, 27.4, 29.2,...\n",
      "Tm       [12.9, 13.7, 17, 16.2, 15.1, 17.8, 19.4, 19, 1...\n",
      "H        [45, 65, 61, 47, 73, 88, 78, 70, 68, 66, 43, 3...\n",
      "PP       [0, 0.51, 4.32, nan, 1.27, 3.3, 0.76, 7.11, 23...\n",
      "VV       [6.3, 5.5, 4.8, 4, 5.3, 6.9, 5.6, 6.6, 7.4, 7....\n",
      "V        [1.1, 0.4, 3.1, 1.3, 0.9, 3, 2.8, 2.6, 1.5, 2....\n",
      "VM       [5.4, 3.5, 7.6, 37, 11.1, 14.8, 18.3, 9.4, 51....\n",
      "RA                                                  [0, 1]\n",
      "TS                                                  [0, 1]\n",
      "FG                                                  [0, 1]\n",
      " pm10    [ , 79, 72, 76, 65, 57, 52, 54, 51, 43, 55, 39...\n",
      " no2     [60, 45, 42, 25, 36, 33, 28,  , 41, 27, 40, 31...\n",
      " so2     [9, 10, 11, 14, 26, 15, 17, 18, 20,  , 30, 32,...\n",
      " co      [15, 13, 11, 6, 5, 4,  , 7, 9, 8, 20, 12, 18, ...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "unique_values = merge_df.apply(pd.Series.unique)\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ebfc7",
   "metadata": {},
   "source": [
    "## Converting All Columns to Numeric Format\n",
    "\n",
    "To ensure the dataset is fully numeric and compatible with machine learning models, we convert all columns to numeric types.\n",
    "\n",
    "### Operation:\n",
    "- `merge_df.apply(pd.to_numeric, errors='coerce')`: Attempts to convert each column to a numeric type.\n",
    "  - Non-numeric entries are coerced to `NaN` (if any exist).\n",
    "\n",
    "### Purpose:\n",
    "- Ensures uniform data types across the dataset.\n",
    "- Prepares the dataset for statistical analysis and modeling.\n",
    "- Handles any leftover non-numeric or malformed entries gracefully by converting them to `NaN`.\n",
    "\n",
    "This step is especially useful after replacing text-based placeholders and ensures the dataset is clean and fully numerical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27fbe50a-e278-4717-9468-d22ce664c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = merge_df.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2bae0",
   "metadata": {},
   "source": [
    "## Final Imputation of Missing Values\n",
    "\n",
    "After converting all columns to numeric types, we perform a final round of missing value imputation using forward and backward fill strategies.\n",
    "\n",
    "### Steps:\n",
    "1. **Create a Copy**:\n",
    "   - `merge_df.copy()`: Ensures we're working on a separate copy of the data to avoid unintended side effects.\n",
    "\n",
    "2. **Forward Fill (`ffill`)**:\n",
    "   - Propagates the last valid observation forward to fill missing values.\n",
    "\n",
    "3. **Backward Fill (`bfill`)**:\n",
    "   - Fills any remaining missing values using the next valid observation.\n",
    "\n",
    "### Purpose:\n",
    "- Ensures a fully populated dataset with no missing values.\n",
    "- Maintains the temporal continuity of the data.\n",
    "- Prepares the final dataset for feature engineering and model training.\n",
    "\n",
    "This step concludes the data cleaning process, ensuring the dataset is consistent, complete, and ready for modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39fb75ee-a57d-44ce-85e9-e1ffda9ccd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = merge_df.copy()\n",
    "merge_df.ffill(inplace=True)\n",
    "merge_df.bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba9c52",
   "metadata": {},
   "source": [
    "## Saving the Cleaned and Merged Dataset\n",
    "\n",
    "After completing all cleaning, preprocessing, and imputation steps, we save the final dataset to a CSV file for future use.\n",
    "\n",
    "### Operation:\n",
    "- `to_csv('merged_df.csv', index=False)`: Exports the DataFrame to a CSV file named `merged_df.csv` without row indices.\n",
    "\n",
    "### Purpose:\n",
    "- Preserves the cleaned dataset for use in modeling, analysis, or deployment.\n",
    "- Allows easy reloading of preprocessed data without repeating the cleaning workflow.\n",
    "\n",
    "This step marks the completion of the data preparation phase and creates a reproducible output for downstream tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6c0f817-1f27-488a-a7df-455cc4c62da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.to_csv('merged_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025dd4ae",
   "metadata": {},
   "source": [
    "## Loading the Final Preprocessed Dataset\n",
    "\n",
    "To begin the modeling phase, we load the cleaned and fully processed dataset from the saved CSV file.\n",
    "\n",
    "### Operation:\n",
    "- `pd.read_csv('merged_df.csv')`: Reads the cleaned dataset into a new DataFrame named `df`.\n",
    "\n",
    "### Purpose:\n",
    "- Ensures a fresh start using the final prepared dataset.\n",
    "- Avoids re-running all preprocessing steps.\n",
    "- Ready for feature engineering, exploratory data analysis, and model training.\n",
    "\n",
    "This marks the transition from data preparation to analysis and predictive modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1575a20e-37ca-4ea5-8cdd-bef2529788a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac85a4",
   "metadata": {},
   "source": [
    "## Previewing the Final Dataset\n",
    "\n",
    "We use `head()` to inspect the first few rows of the fully cleaned and merged dataset loaded into `df`.\n",
    "\n",
    "### Purpose:\n",
    "- Verify the structure and content of the final dataset.\n",
    "- Confirm that all relevant features (weather, pollutants, AQI, etc.) are present and in the expected format.\n",
    "- Ensure that the dataset is ready for feature engineering and model training.\n",
    "\n",
    "This final check confirms the dataset's integrity before proceeding with modeling tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ed7143c-e5bb-4fd0-94fc-43d888151768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>H</th>\n",
       "      <th>PP</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>RA</th>\n",
       "      <th>TS</th>\n",
       "      <th>FG</th>\n",
       "      <th>pm10</th>\n",
       "      <th>no2</th>\n",
       "      <th>so2</th>\n",
       "      <th>co</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>28.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21.4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21.4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>21.4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day     T    TM    Tm   H   PP   VV    V   VM  RA  TS  FG  \\\n",
       "0  2016      1    2  20.8  28.3  12.9  45  0.0  6.3  1.1  5.4   0   0   0   \n",
       "1  2016      1    3  21.4  29.0  13.7  45  0.0  6.3  0.4  3.5   0   0   0   \n",
       "2  2016      1    4  21.4  29.0  13.7  45  0.0  6.3  0.4  3.5   0   0   0   \n",
       "3  2016      1    5  21.4  29.0  13.7  45  0.0  6.3  0.4  3.5   0   0   0   \n",
       "4  2016      1    6  21.4  29.0  13.7  45  0.0  6.3  0.4  3.5   0   0   0   \n",
       "\n",
       "    pm10   no2   so2    co  \n",
       "0   79.0  60.0   9.0  15.0  \n",
       "1   79.0  45.0  10.0  13.0  \n",
       "2   72.0  45.0  11.0  13.0  \n",
       "3   76.0  42.0  14.0  11.0  \n",
       "4   65.0  25.0  26.0   6.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2bedda",
   "metadata": {},
   "source": [
    "## Inspecting Column Names in the Final Dataset\n",
    "\n",
    "We check the list of column names in the DataFrame to identify available features and detect any formatting issues.\n",
    "\n",
    "### Columns Present:\n",
    "- **Date Features**: `Year`, `Month`, `Day`\n",
    "- **Weather Features**: `T`, `TM`, `Tm`, `H`, `PP`, `VV`, `V`, `VM`, `RA`, `TS`, `FG`\n",
    "- **Air Pollutants**: `' pm10'`, `' no2'`, `' so2'`, `' co'`\n",
    "\n",
    "### Observations:\n",
    "- Some pollutant columns have **leading spaces** in their names (`' pm10'`, `' no2'`, etc.), which should be cleaned for consistency and to avoid errors in processing.\n",
    "\n",
    "Cleaning the column names will be the next step to standardize and simplify the dataset before further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1852d9a-db0b-4e53-9869-99d9c8f47bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Day', 'T', 'TM', 'Tm', 'H', 'PP', 'VV', 'V', 'VM',\n",
       "       'RA', 'TS', 'FG', ' pm10', ' no2', ' so2', ' co'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847e6d8",
   "metadata": {},
   "source": [
    "## Computing the Air Quality Index (AQI)\n",
    "\n",
    "To derive a target variable for prediction, we calculate the **Air Quality Index (AQI)** based on the maximum value among key pollutant concentrations.\n",
    "\n",
    "### Steps:\n",
    "1. **Select Pollutant Columns**:\n",
    "   - `[' pm10', ' no2', ' so2', ' co']` represent concentrations of various pollutants.\n",
    "   - These columns currently contain leading spaces and should be cleaned later for consistency.\n",
    "\n",
    "2. **Calculate AQI**:\n",
    "   - `df['AQI'] = df[aqi_columns].max(axis=1)` assigns the maximum pollutant concentration in each row as the AQI value.\n",
    "   - This simplification assumes the highest pollutant value drives the overall AQI, which is a common approach when specific AQI computation formulas are not available.\n",
    "\n",
    "### Purpose:\n",
    "- Creates a target variable (`AQI`) for supervised machine learning.\n",
    "- Enables modeling of AQI as a function of weather and pollutant-related features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98620325-efac-4207-b71e-fbb88f1c0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_columns = [' pm10', ' no2', ' so2', ' co']\n",
    "df['AQI']= df[aqi_columns].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e9ac2c",
   "metadata": {},
   "source": [
    "## Saving the Final Dataset with Computed AQI\n",
    "\n",
    "After calculating the AQI column, we save the updated dataset to a new CSV file for use in modeling and analysis.\n",
    "\n",
    "### Operation:\n",
    "- `df.to_csv('aqidataset.csv', index=False)`: Exports the dataset, including the new `AQI` column, to a CSV file named `aqidataset.csv` without row indices.\n",
    "\n",
    "### Purpose:\n",
    "- Preserves the final, feature-rich dataset with the AQI target variable.\n",
    "- Enables consistent and reusable input for model development pipelines.\n",
    "- Avoids repeating preprocessing and AQI computation steps in the future.\n",
    "\n",
    "This concludes the data preparation process and finalizes the dataset for machine learning tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caa70a63-6192-4336-aae0-1e900ba23e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('aqidataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50364f38",
   "metadata": {},
   "source": [
    "## Loading the Final AQI Dataset for Modeling\n",
    "\n",
    "We load the dataset containing all cleaned features and the computed `AQI` target variable.\n",
    "\n",
    "### Operation:\n",
    "- `pd.read_csv('aqidataset.csv')`: Reads the previously saved CSV file into a DataFrame named `df`.\n",
    "\n",
    "### Purpose:\n",
    "- Marks the starting point for model training and evaluation.\n",
    "- Ensures all features and the `AQI` column are readily available for analysis and machine learning.\n",
    "- Avoids repeating any previous preprocessing steps.\n",
    "\n",
    "This step initiates the modeling phase using the finalized dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015f0e59-ba55-47fd-a4e4-895e398aa531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('aqidataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03522385-dc6b-4fa2-b8f4-47a3d8aeb8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>H</th>\n",
       "      <th>PP</th>\n",
       "      <th>VV</th>\n",
       "      <th>V</th>\n",
       "      <th>VM</th>\n",
       "      <th>RA</th>\n",
       "      <th>TS</th>\n",
       "      <th>FG</th>\n",
       "      <th>pm10</th>\n",
       "      <th>no2</th>\n",
       "      <th>so2</th>\n",
       "      <th>co</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.8</td>\n",
       "      <td>28.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21.4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21.4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>21.4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day     T    TM    Tm   H   PP   VV    V   VM  RA  TS  FG  \\\n",
       "0  2016      1    2  20.8  28.3  12.9  45  0.0  6.3  1.1  5.4   0   0   0   \n",
       "1  2016      1    3  21.4  29.0  13.7  45  0.0  6.3  0.4  3.5   0   0   0   \n",
       "2  2016      1    4  21.4  29.0  13.7  45  0.0  6.3  0.4  3.5   0   0   0   \n",
       "3  2016      1    5  21.4  29.0  13.7  45  0.0  6.3  0.4  3.5   0   0   0   \n",
       "4  2016      1    6  21.4  29.0  13.7  45  0.0  6.3  0.4  3.5   0   0   0   \n",
       "\n",
       "    pm10   no2   so2    co   AQI  \n",
       "0   79.0  60.0   9.0  15.0  79.0  \n",
       "1   79.0  45.0  10.0  13.0  79.0  \n",
       "2   72.0  45.0  11.0  13.0  72.0  \n",
       "3   76.0  42.0  14.0  11.0  76.0  \n",
       "4   65.0  25.0  26.0   6.0  65.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56fea8c8-ac38-43f0-a660-7eae06a5ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2726 entries, 0 to 2725\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Year    2726 non-null   int64  \n",
      " 1   Month   2726 non-null   int64  \n",
      " 2   Day     2726 non-null   int64  \n",
      " 3   T       2726 non-null   float64\n",
      " 4   TM      2726 non-null   float64\n",
      " 5   Tm      2726 non-null   float64\n",
      " 6   H       2726 non-null   int64  \n",
      " 7   PP      2726 non-null   float64\n",
      " 8   VV      2726 non-null   float64\n",
      " 9   V       2726 non-null   float64\n",
      " 10  VM      2726 non-null   float64\n",
      " 11  RA      2726 non-null   int64  \n",
      " 12  TS      2726 non-null   int64  \n",
      " 13  FG      2726 non-null   int64  \n",
      " 14   pm10   2726 non-null   float64\n",
      " 15   no2    2726 non-null   float64\n",
      " 16   so2    2726 non-null   float64\n",
      " 17   co     2726 non-null   float64\n",
      " 18  AQI     2726 non-null   float64\n",
      "dtypes: float64(12), int64(7)\n",
      "memory usage: 404.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
